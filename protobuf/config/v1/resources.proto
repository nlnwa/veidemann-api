syntax = "proto3";

package veidemann.api.config.v1;

import "google/protobuf/timestamp.proto";
import "google/protobuf/duration.proto";

option go_package = "github.com/nlnwa/veidemann-api-go/config/v1;config";
option java_multiple_files = true;
option java_package = "no.nb.nna.veidemann.api.config.v1";
option java_outer_classname = "ConfigResources";

message ConfigObject {
    string id = 1;
    string apiVersion = 2;
    Kind kind = 3;
    Meta meta = 4;
    oneof spec {
        veidemann.api.config.v1.CrawlEntity crawl_entity = 5;
        veidemann.api.config.v1.Seed seed = 6;
        veidemann.api.config.v1.CrawlJob crawl_job = 7;
        veidemann.api.config.v1.CrawlConfig crawl_config = 8;
        veidemann.api.config.v1.CrawlScheduleConfig crawl_schedule_config = 9;
        veidemann.api.config.v1.BrowserConfig browser_config = 10;
        veidemann.api.config.v1.PolitenessConfig politeness_config = 11;
        veidemann.api.config.v1.BrowserScript browser_script = 12;
        veidemann.api.config.v1.CrawlHostGroupConfig crawl_host_group_config = 13;
        veidemann.api.config.v1.RoleMapping role_mapping = 14;
        veidemann.api.config.v1.Collection collection = 15;
    }
}

enum Kind {
    undefined = 0;
    crawlEntity = 5;
    seed = 6;
    crawlJob = 7;
    crawlConfig = 8;
    crawlScheduleConfig = 9;
    browserConfig = 10;
    politenessConfig = 11;
    browserScript = 12;
    crawlHostGroupConfig = 13;
    roleMapping = 14;
    collection = 15;
}

message Meta {
    string name = 1;
    string description = 2;
    google.protobuf.Timestamp created = 3;
    string created_by = 4;
    google.protobuf.Timestamp last_modified = 5;
    string last_modified_by = 6;
    repeated Label label = 7;
}

message Label {
    string key = 1;
    string value = 2;
}

// Reference to another ConfigObject
message ConfigRef {
    Kind kind = 1;
    string id = 2;
}

// A crawl entity (might be an organisation with one or more seeds)
message CrawlEntity {
}

message Seed {
    veidemann.api.config.v1.ConfigRef entity_ref = 3;
    CrawlScope scope = 4;
    repeated veidemann.api.config.v1.ConfigRef job_ref = 5;
    bool disabled = 18;
}

message CrawlJob {
    veidemann.api.config.v1.ConfigRef schedule_ref = 3;
    CrawlLimitsConfig limits = 4;
    veidemann.api.config.v1.ConfigRef crawl_config_ref = 5;
    bool disabled = 18;
}

message CrawlConfig {
    veidemann.api.config.v1.ConfigRef collection_ref = 6;
    veidemann.api.config.v1.ConfigRef browser_config_ref = 7;
    veidemann.api.config.v1.ConfigRef politeness_ref = 8;
    ExtraConfig extra = 9;
    int32 minimum_dns_ttl_s = 10; // Not implemented
    // The weighting between jobs when two jobs compete on fetching resources from the same hosts.
    // The job will be randomly chosen, but weighted such that if two jobs with weight 1.0 and one job with
    // weight 2.0 compete, then the two first jobs will each have 25% probability of being chosen and the the third
    // job will have 50% probability of being chosen.
    double priority_weight = 11;
}

message ExtraConfig {
    bool extract_text = 5; // Not implemented
    bool create_screenshot = 6;
}

message CrawlScheduleConfig {
    string cron_expression = 3;
    google.protobuf.Timestamp valid_from = 4;
    google.protobuf.Timestamp valid_to = 5;
}

message CrawlScope {
    string surt_prefix = 1;
}

message CrawlLimitsConfig {
    // How deep from a seed to crawl
    int32 depth = 1;
    // Maximum time in seconds allowed for crawl to finish
    int64 max_duration_s = 2;
    // Maximum number of bytes to fetch before ending crawl
    int64 max_bytes = 3;
}

message BrowserConfig {
    string user_agent = 3;
    int32 window_width = 4;
    int32 window_height = 5;
    int64 page_load_timeout_ms = 6;
    // Select scripts by label
    // A string representing a label query. The query matches if at least one label matches the query.
    // If there are multiple queries, then each query must match at least one label.
    // Label quries are case insensitive. The basic format is <code>key:value</code> where both key and value must match.
    // If value ends with <code>&ast;</code> then the key must match and value must match up until the <code>&ast;</code>.
    // If value is empty, all labels matching the key will match.
    // If key is empty, then the matching is done on the value for all keys.
    // If key is empty, then the <code>:</code> might be ommitted.
    // <pre>
    // Examples:
    //   "foo:bar"  - matches exactly labels with key=foo and value=bar
    //   "foo:"     - matches all labels with key=foo
    //   ":bar"     - matches all labels with value=bar
    //   "bar"      - matches all labels with value=bar
    //   "foo:ba*"  - matches labels with key=foo and value starting with ba (e.g. matches bar, but not ber)
    //   ":ba*"     - matches labels with any key and value starting with ba (e.g. matches bar, but not ber)
    //   "ba*"      - matches labels with any key and value starting with ba (e.g. matches bar, but not ber)
    //   ":"        - matches every label
    //   ""         - matches every label
    // </pre>
    repeated string script_selector = 7;
    repeated veidemann.api.config.v1.ConfigRef script_ref = 8;
    map<string, string> headers = 16;
    map<string, string> script_parameters = 17; // Not implemented
    // Max time to wait for network activity
    int64 max_inactivity_time_ms = 18;
}

message PolitenessConfig {
    enum RobotsPolicy {
        // Obey robots.txt on a page level. The requested URI is evaluated, but any embedded resources are
        // fetched without respecting robots.txt
        OBEY_ROBOTS = 0;
        // Ignore robots.txt completely
        IGNORE_ROBOTS = 1;
        // Use submitted robots.txt instead of the one served by the target site. Only the requested URI is
        // evaluated.
        CUSTOM_ROBOTS = 2;
        // Obey robots.txt for all URI's
        OBEY_ROBOTS_CLASSIC = 3;
        // Use submitted robots.txt instead of the one served by the target site. All URI's are
        // evaluated.
        CUSTOM_ROBOTS_CLASSIC = 4;
        // Use submitted robots.txt if no one is served by the target site. Only the requested URI is
        // evaluated.
        CUSTOM_IF_MISSING = 5;
        // Use submitted robots.txt if no one is served by the target site. All URI's are
        // evaluated.
        CUSTOM_IF_MISSING_CLASSIC = 6;
    }
    RobotsPolicy robots_policy = 3;
    int32 minimum_robots_validity_duration_s = 11;
    string custom_robots = 20;
    int64 min_time_between_page_load_ms = 4;
    int64 max_time_between_page_load_ms = 5;
    /**
     * The fetch time of the URI is multiplied with this value to get the delay time before fetching the next URI.
     * If min_time_between_page_load_ms and/or max_time_between_page_load_ms are set, then those values are used as
     * the upper/lower limits for delay.
     * If delay_factor is unset or zero, then a delay_facor of one is assumed. If delay_factor is negative,
     * a delay_factor of zero is assumed.
     */
    float delay_factor = 6;
    int32 max_retries = 7; // The maximum number of retries before giving up fetching a uri
    int32 retry_delay_seconds = 8;
    // Select crawl host groups by label
    // A string representing a label query. The query matches if at least one label matches the query.
    // If there are multiple queries, then each query must match at least one label.
    // Label quries are case insensitive. The basic format is <code>key:value</code> where both key and value must match.
    // If value ends with <code>&ast;</code> then the key must match and value must match up until the <code>&ast;</code>.
    // If value is empty, all labels matching the key will match.
    // If key is empty, then the matching is done on the value for all keys.
    // If key is empty, then the <code>:</code> might be ommitted.
    // <pre>
    // Examples:
    //   "foo:bar"  - matches exactly labels with key=foo and value=bar
    //   "foo:"     - matches all labels with key=foo
    //   ":bar"     - matches all labels with value=bar
    //   "bar"      - matches all labels with value=bar
    //   "foo:ba*"  - matches labels with key=foo and value starting with ba (e.g. matches bar, but not ber)
    //   ":ba*"     - matches labels with any key and value starting with ba (e.g. matches bar, but not ber)
    //   "ba*"      - matches labels with any key and value starting with ba (e.g. matches bar, but not ber)
    //   ":"        - matches every label
    //   ""         - matches every label
    // </pre>
    repeated string crawl_host_group_selector = 9;
    // If true, use hostname instead of ip for politeness
    bool use_hostname = 10;
}

// Message containing a javascript to be run in a browser
message BrowserScript {
    string script = 3;
    repeated string url_regexp = 4;
}

message CrawlHostGroupConfig {
    message IpRange {
        string ip_from = 1;
        string ip_to = 2;
    }
    repeated IpRange ip_range = 3;
}

enum Role {
    // Any authenticated user
    ANY_USER = 0;
    // Any user including unauthenticated users
    ANY = 1;
    // Administrator
    ADMIN = 2;
    // Curator
    CURATOR = 3;
    // A user with permission to read internal data
    READONLY = 4;
    // A crawl operator
    OPERATOR = 5;
    // Machine to machine
    SYSTEM = 6;
}

message ApiKey {
    string api_key=1;
    google.protobuf.Duration validTime=2;
}

message RoleMapping {
    oneof email_or_group {
        ApiKey api_key=1;
        string email = 2;
        string group = 3;
    }
    repeated Role role = 4;
}

message Collection {
    enum RotationPolicy {
        NONE = 0;
        HOURLY = 1;
        DAILY = 2;
        MONTHLY = 3;
        YEARLY = 4;
    }

    enum SubCollectionType {
        UNDEFINED = 0;
        SCREENSHOT = 1;
        DNS = 2;
    }

    message SubCollection {
        SubCollectionType type = 1;
        string name = 2;
    }

    RotationPolicy collection_dedup_policy = 1;
    RotationPolicy file_rotation_policy = 2;
    bool compress = 3;
    int64 file_size = 4;
    repeated SubCollection sub_collections = 10;
}

message LogLevels {
    enum Level {
        UNDEFINED = 0;
        ALL = 1;
        TRACE = 2;
        DEBUG = 3;
        INFO = 4;
        WARN = 5;
        ERROR = 6;
        FATAL = 7;
        OFF = 8;
    }
    message LogLevel {
        string logger = 1;
        Level level = 2;
    }
    repeated LogLevel log_level = 1;
}
